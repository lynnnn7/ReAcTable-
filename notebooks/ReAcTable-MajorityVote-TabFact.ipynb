{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fa0fb0-dbd8-4ec5-8b5d-b9c237455edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c67b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetname='TabFact_potable'\n",
    "datasetname='tabfact_cot'\n",
    "# datasetname='WikiTableQuestions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54b74f4-099c-4f47-89f2-305d54d6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tabqa.GptPrompter import *\n",
    "from tabqa.GptCOTPrompter import *\n",
    "from tabqa.GptCOTPrompter_BeamSeach import *\n",
    "from tabqa.AutoReasoner import *\n",
    "import dotenv\n",
    "\n",
    "config = dotenv.dotenv_values(\"../.env\")\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.base_url = config['GPT_BASE_URL']\n",
    "\n",
    "dataset = pd.read_csv('../dataset/'+str(datasetname)+'/data/test.jsonl', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401acaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading tabfact-test dataset: 100%|██████████| 10/10 [00:00<00:00, 11137.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset.tabfact_cot.load_data import load_tabfact_dataset\n",
    "dataset_path='../dataset/'+str(datasetname)+'/data/test.jsonl'\n",
    "raw2clean_path='../dataset/'+str(datasetname)+'/data/raw2clean.jsonl'\n",
    "first_n=10\n",
    "dataset = load_tabfact_dataset(dataset_path, raw2clean_path, first_n=first_n)\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b22a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date              Event Duration\\n(months) Duration\\n(years)\n",
      "0              1927  Experiment set up                NaN               NaN\n",
      "1              1930   The stem was cut                NaN               NaN\n",
      "2     December 1938      1st drop fell             96–107           8.0–8.9\n",
      "3     February 1947      2nd drop fell                 99               8.2\n",
      "4        April 1954      3rd drop fell                 86               7.2\n",
      "5          May 1962      4th drop fell                 97               8.1\n",
      "6       August 1970      5th drop fell                 99               8.3\n",
      "7        April 1979      6th drop fell                104               8.7\n",
      "8         July 1988      7th drop fell                111               9.2\n",
      "9  28 November 2000      8th drop fell                148              12.3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  game     date        opponent result wildcats points opponents      record\n",
      "0    1  sept 20        ole miss   loss               7        14       0 - 1\n",
      "1    2  sept 27      cincinnati    win              20         0       1 - 1\n",
      "2    3    oct 4          xavier    win              20         7       2 - 1\n",
      "3    4   oct 11       9 georgia    win              26         0  3 - 1 , 20\n",
      "4    5   oct 18   10 vanderbilt    win              14         0  4 - 1 , 14\n",
      "5    6   oct 25  michigan state    win               7         6  5 - 1 , 13\n",
      "6    7    nov 1      18 alabama   loss               0        13       5 - 2\n",
      "7    8    nov 8   west virginia    win              15         6       6 - 2\n",
      "8    9   nov 15      evansville    win              36         0       7 - 2\n",
      "9   10   nov 22       tennessee   loss               6        13       7 - 3\n"
     ]
    }
   ],
   "source": [
    "aa = pd.read_csv('../dataset/WikiTableQuestions/csv/200-csv/47.csv', on_bad_lines='skip', sep=\",\")\n",
    "print(aa)\n",
    "print(type(aa))\n",
    "# 提取列名\n",
    "columns = x[0]\n",
    "# 转换为 DataFrame\n",
    "y = pd.DataFrame(x[1:], columns=columns)\n",
    "# y= pd.DataFrame(x)\n",
    "print(type(y))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ad51ccf-cda6-47ed-8fb9-8f7f60343867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1007.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NNDemo = False\n",
    "max_demo = 8\n",
    "# gpt_model = 'gpt-4o-mini'\n",
    "gpt_model = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "\n",
    "program = 'sql-py'\n",
    "template = 'original-sql-py-no-intermediate'\n",
    "\n",
    "def parallel_codex_func_formatv1(i):\n",
    "    max_retry = 3\n",
    "    while max_retry>0:\n",
    "        try:\n",
    "            codex_prompter = CodexAnswerCOTExecutor_HighTemperaturMajorityVote(\n",
    "                                                f'prompt_template/{template}.json',\n",
    "                                                dataset.iloc[i]['id'], \n",
    "                                                dataset.iloc[i]['statement '], \n",
    "                                                dataset.iloc[i]['table_text'], \n",
    "                                                dataset.iloc[i]['label'],  \n",
    "                                                base_path=f'../dataset/{datasetname}/',\n",
    "                                                demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                                )\n",
    "            codex_prompter.max_demo = max_demo\n",
    "            codex_prompter.model = gpt_model\n",
    "            codex_prompter._gen_gpt_prompt(NNDemo) #使用 table_formater 函数格式化 source_table_df \n",
    "            codex_prompter._get_gpt_prediction_majority_vote(repeat_times=5)\n",
    "            log = codex_prompter._log_dict()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            log = {\n",
    "                'id': dataset.iloc[i]['id'],\n",
    "                'uncaught_err': str(e)\n",
    "            }\n",
    "            if \"model's maximum context length\" in str(e):\n",
    "                return log\n",
    "            max_retry -= 1\n",
    "    print(\"YES\")\n",
    "    return log\n",
    "    \n",
    "n_threads = 3\n",
    "maxLimit = 8\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "output_result_file = f'../dataset/{datasetname}/results/CodexAnswerCOTExecutor_HighTemperaturMajorityVote_{template}_{program}_NNDemo={NNDemo}_results_pristine-unseen-tables_limit{maxLimit}_model{gpt_model.split(\"/\")[-1]}.json'\n",
    "output_result_file = f'../dataset/{datasetname}/results/ipy_1.json'\n",
    "\n",
    "output_dir = os.path.dirname(output_result_file)  # 获取文件的目录部分\n",
    "if not os.path.exists(output_dir):  # 如果目录不存在\n",
    "    os.makedirs(output_dir)  # 创建目录\n",
    "logs = Parallel(n_jobs=n_threads, require='sharedmem')(delayed(parallel_codex_func_formatv1)(i) for i in tqdm(range(min(maxLimit, dataset.shape[0]))))    \n",
    "json.dump(logs, open(output_result_file, 'w'), indent=4)\n",
    "print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2aad32ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'test-0', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-1', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-2', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-3', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-4', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-5', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-6', 'uncaught_err': \"'statement '\"},\n",
       " {'id': 'test-7', 'uncaught_err': \"'statement '\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a05ddc-a700-4062-85ac-7f70ecd46e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"evaluate.py\", line 61\n",
      "    print(f\"Error\")\n",
      "                 ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate: \n",
    "os.system(f'cd ../dataset/{datasetname}/ && python2 evaluate.py ./results/{output_result_file.split(\"/\")[-1]} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reactable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
