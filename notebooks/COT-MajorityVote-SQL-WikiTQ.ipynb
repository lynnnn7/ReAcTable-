{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7fa0fb0-dbd8-4ec5-8b5d-b9c237455edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54b74f4-099c-4f47-89f2-305d54d6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "# from gpt3_sandbox.api.gpt import GPT\n",
    "# from gpt3_sandbox.api.gpt import Example\n",
    "from pandasql import sqldf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from GptPrompter import *\n",
    "from GptCOTPrompter import *\n",
    "from GptCOTPrompter_BeamSeach import *\n",
    "from AutoReasoner import *\n",
    "import dotenv\n",
    "import traceback\n",
    "\n",
    "config = dotenv.dotenv_values(\".env\")\n",
    "openai.api_type = 'azure'\n",
    "openai.api_base = 'https://meta-prompter-az-openai.openai.azure.com'\n",
    "openai.api_version = '2022-12-01'\n",
    "openai.api_key = config['OPENAI_API_KEY_ms']\n",
    "\n",
    "# dataset = pd.read_csv('./dataset/WikiTableQuestions/data/pristine-unseen-tables-sample400.tsv', sep='\\t')\n",
    "dataset = pd.read_csv('./dataset/WikiTableQuestions/data/pristine-unseen-tables.tsv', sep='\\t')\n",
    "# dataset = pd.read_csv('./dataset/WikiTableQuestions/data/training.tsv', sep='\\t')\n",
    "ft = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793811e9-8737-4d8f-bcbb-274e539de27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "# ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213c2d0-01ac-4508-b553-0a58a2ecb067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad51ccf-cda6-47ed-8fb9-8f7f60343867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                                                                                                                                                         | 0/100 [00:00<?, ?it/s]\u001b[AProcess Process-1164:\n",
      "Process Process-1162:\n",
      "Process Process-1165:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m     45\u001b[0m output_result_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/WikiTableQuestions/results/CodexAnswerCOTExecutor_HighTemperaturMajorityVote_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprogram\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_NNDemo=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNNDemo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_pristine-unseen-tables_limit\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxLimit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpt_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 46\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_codex_func_formatv1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaxLimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     47\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(logs, \u001b[38;5;28mopen\u001b[39m(output_result_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# evaluate: \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/GPT-TabQA/GptConnector.py\", line 123, in gpt\n",
      "    output = openai.Completion.create(\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/GPT-TabQA/GptConnector.py\", line 123, in gpt\n",
      "    output = openai.Completion.create(\n",
      "  File \"/mnt/GPT-TabQA/GptConnector.py\", line 123, in gpt\n",
      "    output = openai.Completion.create(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\", line 216, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\", line 216, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\", line 216, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\", line 516, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\", line 516, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\", line 516, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# TODO: 1) add more examples for python, 2) balance the length, 3) split the steps, first step SQL etc\n",
    "\n",
    "NNDemo = False\n",
    "max_demo = 5\n",
    "# template = 'original-sql-py'\n",
    "template = 'original-sql-py-no-intermediate'\n",
    "# gpt_model = 'text-davinci-003'\n",
    "gpt_model = 'mp-aoi-codex'\n",
    "\n",
    "def parallel_codex_func_formatv1(i):\n",
    "    max_retry = 3\n",
    "    while max_retry>0:\n",
    "        try:\n",
    "            codex_prompter = CodexAnswerCOTExecutor_HighTemperaturMajorityVote(\n",
    "                                              f'prompt_template/{template}.json',\n",
    "                                              dataset.iloc[i]['id'], \n",
    "                                              dataset.iloc[i]['utterance'], \n",
    "                                              dataset.iloc[i]['context'], \n",
    "                                              dataset.iloc[i]['targetValue'],  \n",
    "                                              base_path='./dataset/WikiTableQuestions/',\n",
    "                                              demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                             )\n",
    "            codex_prompter.max_demo = max_demo\n",
    "            # codex_prompter.demo_ids = [0, 1, 2, 3, 6, 8, 11]\n",
    "            codex_prompter.model = gpt_model\n",
    "            codex_prompter._gen_gpt_prompt(NNDemo, ft)\n",
    "            codex_prompter._get_gpt_prediction_majority_vote(repeat_times=5)\n",
    "            log = codex_prompter._log_dict()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            log = {\n",
    "                'id': dataset.iloc[i]['id'],\n",
    "                'uncaught_err': str(e)\n",
    "            }\n",
    "            if \"model's maximum context length\" in str(e):\n",
    "                return log\n",
    "            max_retry -= 1\n",
    "    return log\n",
    "    \n",
    "for program in [ 'sql-py']:\n",
    "    n_threads = 1\n",
    "    maxLimit = float('inf')\n",
    "    # maxLimit = 100\n",
    "    from joblib import Parallel, delayed\n",
    "    output_result_file = f'./dataset/WikiTableQuestions/results/CodexAnswerCOTExecutor_HighTemperaturMajorityVote_{template}_{program}_NNDemo={NNDemo}_results_pristine-unseen-tables_limit{maxLimit}_model{gpt_model}.json'\n",
    "    logs = Parallel(n_jobs=n_threads, require='sharedmem')(delayed(parallel_codex_func_formatv1)(i) for i in tqdm(range(min(maxLimit, dataset.shape[0]))))    \n",
    "    json.dump(logs, open(output_result_file, 'w'), indent=4)\n",
    "    # evaluate: \n",
    "    os.system(f'cd ./dataset/WikiTableQuestions/ && python2 evaluator.py ./results/{output_result_file.split(\"/\")[-1]} && cd ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcc71493-de7d-44a9-8bb0-000942e720e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNDemo = False\n",
    "max_demo = 5\n",
    "template = 'original-sql-py'\n",
    "program = 'sql-py'\n",
    "def func(i):\n",
    "    codex_prompter = CodexAnswerCOTExecutor_HighTemperaturMajorityVote(\n",
    "                                              f'prompt_template/{template}.json',\n",
    "                                              dataset.iloc[i]['id'], \n",
    "                                              dataset.iloc[i]['utterance'], \n",
    "                                              dataset.iloc[i]['context'], \n",
    "                                              dataset.iloc[i]['targetValue'],  \n",
    "                                              base_path='./dataset/WikiTableQuestions/',\n",
    "                                              demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                             )\n",
    "    codex_prompter.max_demo = max_demo\n",
    "    # codex_prompter._gen_gpt_prompt()\n",
    "    # codex_prompter._gen_gpt_prompt(NNDemo, ft)\n",
    "    # codex_prompter._get_gpt_prediction()\n",
    "    codex_prompter._get_gpt_prediction_majority_vote()\n",
    "    log = codex_prompter._log_dict()\n",
    "    return log\n",
    "a = func(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a05ddc-a700-4062-85ac-7f70ecd46e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
