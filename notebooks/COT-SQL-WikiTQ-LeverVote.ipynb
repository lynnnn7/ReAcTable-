{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fa0fb0-dbd8-4ec5-8b5d-b9c237455edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54b74f4-099c-4f47-89f2-305d54d6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "# from gpt3_sandbox.api.gpt import GPT\n",
    "# from gpt3_sandbox.api.gpt import Example\n",
    "from pandasql import sqldf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from GptPrompter import *\n",
    "from GptCOTPrompter import *\n",
    "from GptCOTPrompter_BeamSeach import *\n",
    "from AutoReasoner import *\n",
    "import dotenv\n",
    "\n",
    "config = dotenv.dotenv_values(\".env\")\n",
    "openai.api_type = 'azure'\n",
    "openai.api_base = 'https://meta-prompter-az-openai.openai.azure.com'\n",
    "openai.api_version = '2022-12-01'\n",
    "openai.api_key = config['OPENAI_API_KEY_ms']\n",
    "\n",
    "# print(openai.Model.list())\n",
    "dataset = pd.read_csv('./dataset/WikiTableQuestions/data/pristine-unseen-tables.tsv', sep='\\t')\n",
    "# dataset = pd.read_csv('./dataset/WikiTableQuestions/data/pristine-unseen-tables-sample400.tsv', sep='\\t')\n",
    "# dataset = pd.read_csv('./dataset/WikiTableQuestions/data/training.tsv', sep='\\t')\n",
    "ft = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "793811e9-8737-4d8f-bcbb-274e539de27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "# ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3213c2d0-01ac-4508-b553-0a58a2ecb067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f7e375-ef7d-40ae-b0c8-0551d93e6c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "Reading dataset from ./tagged/data/training.tagged\n",
      "Reading dataset from ./tagged/data/pristine-seen-tables.tagged\n",
      "Reading dataset from ./tagged/data/pristine-unseen-tables.tagged\n",
      "Read 22033 examples\n",
      "Reading predictions from ./results/CodexAnswerCOTExecutor_LeverVote_original-sql-py-no-intermediate_sql-py_NNDemo=False_results_pristine-unseen-tables_limit1_modelmp-aoi-codex.json\n",
      "Examples: 1\n",
      "Correct: 0\n",
      "Accuracy: 0.0\n",
      "GPT error: 0.0\n",
      "Uncaught error: 0.0\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "NNDemo = False\n",
    "max_demo = 5\n",
    "# template = 'original-sql-py'\n",
    "template = 'original-sql-py-no-intermediate'\n",
    "# template = 'formatv1-sql-py'\n",
    "\n",
    "# gpt_model = 'text-davinci-003'\n",
    "gpt_model = 'mp-aoi-codex'\n",
    "# gpt_model = 'gpt-3.5-turbo'\n",
    "\n",
    "def parallel_codex_func_formatv1(i):\n",
    "    max_retry = 3\n",
    "    while max_retry>0:\n",
    "        try:\n",
    "            codex_prompter = CodexAnswerCOTExecutor_LeverVote(\n",
    "                                              f'prompt_template/{template}.json',\n",
    "                                              dataset.iloc[i]['id'], \n",
    "                                              dataset.iloc[i]['utterance'], \n",
    "                                              dataset.iloc[i]['context'], \n",
    "                                              dataset.iloc[i]['targetValue'],  \n",
    "                                              base_path='./dataset/WikiTableQuestions/',\n",
    "                                              demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                             )\n",
    "            codex_prompter.model = gpt_model\n",
    "            codex_prompter.max_demo = max_demo\n",
    "            \n",
    "            codex_prompter._gen_gpt_prompt(NNDemo, ft)\n",
    "            codex_prompter._get_gpt_prediction(5)\n",
    "            log = codex_prompter._log_dict()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            log = {\n",
    "                'id': dataset.iloc[i]['id'],\n",
    "                'uncaught_err': str(e)\n",
    "            }\n",
    "            if \"model's maximum context length\" in str(e):\n",
    "                return log\n",
    "            max_retry -= 1\n",
    "    return log\n",
    "    \n",
    "for program in ['sql-py']:\n",
    "    n_threads = 1\n",
    "    maxLimit = float('inf')\n",
    "    # maxLimit = 1\n",
    "    from joblib import Parallel, delayed\n",
    "    output_result_file = f'./dataset/WikiTableQuestions/results/CodexAnswerCOTExecutor_LeverVote_{template}_{program}_NNDemo={NNDemo}_results_pristine-unseen-tables_limit{maxLimit}_model{gpt_model}.json'\n",
    "    logs = Parallel(n_jobs=n_threads, require='sharedmem')(delayed(parallel_codex_func_formatv1)(i) for i in tqdm(range(min(maxLimit, dataset.shape[0]))))\n",
    "    json.dump(logs, open(output_result_file, 'w'), indent=4)\n",
    "    # evaluate: \n",
    "    os.system(f'cd ./dataset/WikiTableQuestions/ && python2 evaluator.py ./results/{output_result_file.split(\"/\")[-1]} && cd ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc71493-de7d-44a9-8bb0-000942e720e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NNDemo = False\n",
    "max_demo = 5\n",
    "template = 'original-sql-py-no-intermediate'\n",
    "program = 'sql-py'\n",
    "# gpt_model = 'text-davinci-003'\n",
    "gpt_model = 'mp-aoi-codex'\n",
    "\n",
    "def func(i):\n",
    "    codex_prompter = CodexAnswerCOTExecutor_LeverVote(\n",
    "                                      f'prompt_template/{template}.json',\n",
    "                                      dataset.iloc[i]['id'], \n",
    "                                      dataset.iloc[i]['utterance'], \n",
    "                                      dataset.iloc[i]['context'], \n",
    "                                      dataset.iloc[i]['targetValue'],  \n",
    "                                      base_path='./dataset/WikiTableQuestions/',\n",
    "                                      demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                     )\n",
    "    codex_prompter.model = gpt_model\n",
    "    codex_prompter.max_demo = max_demo\n",
    "    codex_prompter.demo_ids = [0, 1, 2, 3, 6, 8, 11]\n",
    "\n",
    "\n",
    "    # codex_prompter._gen_gpt_prompt()\n",
    "    codex_prompter._gen_gpt_prompt(NNDemo, ft)\n",
    "    codex_prompter._get_gpt_prediction(5)\n",
    "    log = codex_prompter._log_dict()\n",
    "    # print(vars(codex_prompter))\n",
    "    # print(codex_prompter.frequency_penalty)\n",
    "    return log\n",
    "a = func(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "720442cb-7e13-4bcb-9b19-3f160a619447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'nu-0',\n",
       " 'utterance': 'which country had the most cyclists finish within the top 10?',\n",
       " 'source_csv': './dataset/WikiTableQuestions/csv/203-csv/733.csv',\n",
       " 'target_value': 'Italy',\n",
       " 'predicted_value': 'ESP',\n",
       " 'prompt': 'The database table DF is shown as follows:\\n[HEAD]: name|c_1989|c_1990|c_1991|c_1992|c_1993|c_1994|c_1995|c_1996|c_1997|c_1998|c_1999|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|career_sr|career_win_loss\\n---\\n[ROW] 1: Australian Open|A|A|1R|A|2R|3R|2R|1R|A|3R|4R|1R|2R|1R|3R|2R|1R|QF|3R|2R|3R|1R|0 / 18|22–18\\n[ROW] 2: French Open|1R|2R|4R|1R|1R|3R|1R|A|1R|3R|1R|2R|4R|2R|2R|3R|1R|1R|1R|2R|1R|A|0 / 20|17–20\\n[ROW] 3: Wimbledon|A|1R|A|A|A|A|1R|A|1R|A|2R|2R|3R|2R|2R|2R|2R|2R|2R|1R|2R|A|0 / 14|11–14\\n...\\n[ROW] 17: Annual Win-Loss|nan|2–4|7–5|3–5|6–4|2–1|5–4|2–1|12–6|10–9|10–7|12–9|13–9|9–9|2–7|8–5|7–7|3–8|4–3|2–3|1–2|0–0|nan|120–108\\n[ROW] 18: Year End Ranking|235|62|43|43|55|46|102|118|29|41|34|31|22|35|62|52|58|52|37|52|68|–|nan|nan\\n\\nAnswer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Generate SQL or Python code step-by-step given the question and table to answer the question correctly. For each step, generate SQL code to process the query or Python code to reformat the data. Output the code braced by \"```\" and an external executor will process the code generated and feed an intermediate table back to you. Answer the question directly if confident.\\n\\nSQL: ```SELECT name, career_win_loss FROM DF WHERE name=\"Australian Open\" or name=\"Indian Wells\";```.\\n\\nIntermediate table:\\n[HEAD]: career_win_loss\\n---\\n[ROW] 1: Australian Open|22–18\\n[ROW] 2: Indian Wells|16-13\\n\\nAnswer: ```Australian Open```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: by_race|white|black|aian*|asian|nhpi*\\n---\\n[ROW] 1: 2000 (total population)|75.43%|4.46%|19.06%|5.24%|0.88%\\n[ROW] 2: 2000 (Hispanic only)|3.42%|0.33%|0.45%|0.16%|0.06%\\n[ROW] 3: 2005 (total population)|74.71%|4.72%|18.77%|5.90%|0.88%\\n...\\n[ROW] 6: Growth 2000–05 (non-Hispanic only)|3.49%|11.30%|4.02%|18.96%|5.86%\\n[ROW] 7: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\\n\\nAnswer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Generate SQL or Python code step-by-step given the question and table to answer the question correctly. For each step, generate SQL code to process the query or Python code to reformat the data. Output the code braced by \"```\" and an external executor will process the code generated and feed an intermediate table back to you. Answer the question directly if confident.\\n\\nSQL: ```SELECT * FROM DF WHERE by_race LIKE \"Growth 2000–05 (Hispanic only)%\";```.\\n\\nIntermediate table:\\n[HEAD]: by_race|white|black|aian*|asian|nhpi*\\n---\\n[ROW] 1: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\\n\\nAnswer: ```white```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: rank|mountain_peak|mountain_range|elevation|prominence|isolation|location\\n---\\n[ROW] 1: 1|Mount Whitney|Sierra Nevada|14,505 ft 4421 m|10,080 ft 3072 m|1,646 mi 2,649 km|36°34′43″N 118°17′31″W\\ufeff / \\ufeff36.5786°N 118.2920°W\\n[ROW] 2: 2|Mount Williamson|Sierra Nevada|14,379 ft 4383 m|1,677 ft 511 m|5.4 mi 8.7 km|36°39′21″N 118°18′40″W\\ufeff / \\ufeff36.6559°N 118.3111°W\\n[ROW] 3: 3|White Mountain Peak|White Mountains|14,252 ft 4344 m|7,196 ft 2193 m|67 mi 109 km|37°38′03″N 118°15′21″W\\ufeff / \\ufeff37.6341°N 118.2557°W\\n...\\n[ROW] 15: 15|Red Slate Mountain|Sierra Nevada|13,162 ft 4012 m|1,736 ft 529 m|8 mi 13 km|37°30′27″N 118°52′09″W\\ufeff / \\ufeff37.5075°N 118.8693°W\\n[ROW] 16: 16|Mount Ritter|Sierra Nevada|13,149 ft 4008 m|3,990 ft 1216 m|22 mi 35 km|37°41′21″N 119°11′59″W\\ufeff / \\ufeff37.6891°N 119.1996°W\\n\\nAnswer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Generate SQL or Python code step-by-step given the question and table to answer the question correctly. For each step, generate SQL code to process the query or Python code to reformat the data. Output the code braced by \"```\" and an external executor will process the code generated and feed an intermediate table back to you. Answer the question directly if confident.\\n\\nSQL: ```SELECT mountain_peak, prominence FROM DF;```.\\n\\nIntermediate table:\\n[HEAD]: mountain_peak|prominence\\n---\\n[ROW] 1: Mount Whitney|10,080 ft 3072 m\\n[ROW] 2: Mount Williamson|1,677 ft 511 m\\n[ROW] 3: White Mountain Peak|7,196 ft 2193 m\\n...\\n[ROW] 15: Red Slate Mountain|1,736 ft 529 m\\n[ROW] 16: Mount Ritter|3,990 ft 1216 m\\n\\nPython: ```def get_ft(s):\\n    import re\\n    return float(re.search(\"(.*?) ft\", s).group(1))\\nDF[\\'prominence_ft\\'] = DF.apply(lambda x: get_ft(x[\\'prominence\\']), axis=1)\\n```.\\n\\nIntermediate table:\\n[HEAD]: mountain_peak|prominence|prominence_ft\\n---\\n[ROW] 1: Mount Whitney|10,080 ft 3072 m|10080.0\\n[ROW] 2: Mount Williamson|1,677 ft 511 m|1677.0\\n[ROW] 3: White Mountain Peak|7,196 ft 2193 m|7196.0\\n...\\n[ROW] 15: Red Slate Mountain|1,736 ft 529 m|1736.0\\n[ROW] 16: Mount Ritter|3,990 ft 1216 m|3990.0\\n\\nSQL: ```SELECT mountain_peak FROM DF WHERE prominence_ft>10000;```.\\n\\nIntermediate table:\\n[HEAD]: mountain_peak\\n---\\n[ROW] 1: Mount Whitney\\n\\nAnswer: ```Mount Whitney```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: season|division|tms|pos|fa_cup|afc_cl\\n---\\n[ROW] 1: 2003|1|12|11|Quarter final|-\\n[ROW] 2: 2004|1|13|10|Round of 32|-\\n[ROW] 3: 2005|1|13|8|Quarter final|-\\n...\\n[ROW] 9: 2011|1|16|12|Round of 32|-\\n[ROW] 10: 2012|1|16|10|Round of 16|-\\n\\nAnswer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Generate SQL or Python code step-by-step given the question and table to answer the question correctly. For each step, generate SQL code to process the query or Python code to reformat the data. Output the code braced by \"```\" and an external executor will process the code generated and feed an intermediate table back to you. Answer the question directly if confident.\\n\\nSQL: ```SELECT fa_cup FROM DF WHERE season>2009;```.\\n\\nIntermediate table:\\n[HEAD]: fa_cup\\n---\\n[ROW] 1: Round of 32\\n[ROW] 2: Round of 32\\n[ROW] 3: Round of 16\\n\\nAnswer: ```Round of 16```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: unnamed_0|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|c_2011|c_2012\\n---\\n[ROW] 1: Hydro power|1,150|1,161|1,171|1,247|1,281|1,293|1,316|1,326|1,357|1,379|1,382|1,401|1,584\\n[ROW] 2: Thermal|685|835|1,056|1,233|1,215|1,155|1,155|1,155|1,285|1,290|1,390|1,690|1,638\\n[ROW] 3: Other renewables|3|3|3|3|3|3|3|3|3|15|45|50|90\\n...\\n[ROW] 7: Other renewables|3|3|4|3|3|5|4|4|8|27|86|121|169\\n[ROW] 8: Total production|6,685|6,520|6,167|7,611|8,043|8,770|9,389|9,815|9,901|9,883|10,715|11,528|11,800\\n\\nAnswer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Generate SQL or Python code step-by-step given the question and table to answer the question correctly. For each step, generate SQL code to process the query or Python code to reformat the data. Output the code braced by \"```\" and an external executor will process the code generated and feed an intermediate table back to you. Answer the question directly if confident.\\n\\nSQL: ```SELECT c_2010, c_2012 FROM DF WHERE unnamed_0=\"Hydro power\";```.\\n\\nIntermediate table:\\n[HEAD]: c_2010|c_2012\\n---\\n[ROW] 1: 1,382|1,584\\n\\nAnswer: ```increase```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: rank|cyclist|team|time|uci_protour_points\\n---\\n[ROW] 1: 1|Alejandro Valverde (ESP)|Caisse d\\'Epargne|5h 29\\' 10\\\\\",40\"|NULL\\n[ROW] 2: 2|Alexandr Kolobnev (RUS)|Team CSC Saxo Bank|s.t.|30.0\\n[ROW] 3: 3|Davide Rebellin (ITA)|Gerolsteiner|s.t.|25.0\\n[ROW] 4: 4|Paolo Bettini (ITA)|Quick Step|s.t.|20.0\\n[ROW] 5: 5|Franco Pellizotti (ITA)|Liquigas|s.t.|15.0\\n[ROW] 6: 6|Denis Menchov (RUS)|Rabobank|s.t.|11.0\\n[ROW] 7: 7|Samuel Sánchez (ESP)|Euskaltel-Euskadi|s.t.|7.0\\n[ROW] 8: 8|Stéphane Goubert (FRA)|Ag2r-La Mondiale|+ 2\\\\\",5\"|NULL\\n[ROW] 9: 9|Haimar Zubeldia (ESP)|Euskaltel-Euskadi|+ 2\\\\\",3\"|NULL\\n[ROW] 10: 10|David Moncoutié (FRA)|Cofidis|+ 2\\\\\",1\"|NULL\\n\\nAnswer the following question based on the data above: \"which country had the most cyclists finish within the top 10?\". Generate SQL or Python code step-by-step given the question and table to answer the question correctly. For each step, generate SQL code to process the query or Python code to reformat the data. Output the code braced by \"```\" and an external executor will process the code generated and feed an intermediate table back to you. Answer the question directly if confident.\\n\\nSQL: ```SELECT cyclist FROM DF;```.\\n\\nIntermediate table:\\n[HEAD]: cyclist\\n---\\n[ROW] 1: Alejandro Valverde (ESP)\\n[ROW] 2: Alexandr Kolobnev (RUS)\\n[ROW] 3: Davide Rebellin (ITA)\\n[ROW] 4: Paolo Bettini (ITA)\\n[ROW] 5: Franco Pellizotti (ITA)\\n[ROW] 6: Denis Menchov (RUS)\\n[ROW] 7: Samuel Sánchez (ESP)\\n[ROW] 8: Stéphane Goubert (FRA)\\n[ROW] 9: Haimar Zubeldia (ESP)\\n[ROW] 10: David Moncoutié (FRA)\\n\\nPython: ```def get_country(s):\\n    import re\\n    return re.search(\"\\\\((.*?)\\\\)\", s).group(1)\\nDF[\\'country\\'] = DF.apply(lambda x: get_country(x[\\'cyclist\\']), axis=1)```.\\n\\nIntermediate table:\\n[HEAD]: cyclist|country\\n---\\n[ROW] 1: Alejandro Valverde (ESP)|ESP\\n[ROW] 2: Alexandr Kolobnev (RUS)|RUS\\n[ROW] 3: Davide Rebellin (ITA)|ITA\\n[ROW] 4: Paolo Bettini (ITA)|ITA\\n[ROW] 5: Franco Pellizotti (ITA)|ITA\\n[ROW] 6: Denis Menchov (RUS)|RUS\\n[ROW] 7: Samuel Sánchez (ESP)|ESP\\n[ROW] 8: Stéphane Goubert (FRA)|FRA\\n[ROW] 9: Haimar Zubeldia (ESP)|ESP\\n[ROW] 10: David Moncoutié (FRA)|FRA\\n\\nSQL: ```SELECT country, count(*) FROM DF GROUP BY country;```.\\n\\nIntermediate table:\\n[HEAD]: country|count(*)\\n---\\n[ROW] 1: ESP|3\\n[ROW] 2: FRA|2\\n[ROW] 3: ITA|3\\n[ROW] 4: RUS|2\\n\\nAnswer: ```ESP```.',\n",
       " 'execution_match': None,\n",
       " 'gpt_error': None,\n",
       " 'execution_err': None,\n",
       " 'predicted_sql': None,\n",
       " 'df_reformat_sql': None,\n",
       " 'gpt_original_output': [[],\n",
       "  [(-1.9304140462608044, 'SELECT cyclist FROM DF;'),\n",
       "   (1, 'SELECT cyclist FROM DF;')],\n",
       "  [],\n",
       "  [(96.803810482718,\n",
       "    'def get_country(s):\\n    import re\\n    return re.search(\"\\\\((.*?)\\\\)\", s).group(1)\\nDF[\\'country\\'] = DF.apply(lambda x: get_country(x[\\'cyclist\\']), axis=1)'),\n",
       "   (1,\n",
       "    'def get_country(s):\\n    import re\\n    return re.search(\"\\\\((.*?)\\\\)\", s).group(1)\\nDF[\\'country\\'] = DF.apply(lambda x: get_country(x[\\'cyclist\\']), axis=1)')],\n",
       "  [],\n",
       "  [(-1.6809532253206936, 'SELECT country, count(*) FROM DF GROUP BY country;'),\n",
       "   (1, 'SELECT country, count(*) FROM DF GROUP BY country;')],\n",
       "  [],\n",
       "  [(0.5206976665253911, 'ESP'), (1, 'ESP')]],\n",
       " 'all_predictions': [],\n",
       " 'training_demo_ids': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(a['prompt'])\n",
    "# print(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a24c1-48e3-4f08-8c1a-6d8709a9f0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd3e63-81a1-4fb1-99ef-18d6a2168283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "116ad23c-c5a3-4bb5-b582-ea6363ae60f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<requests.adapters.HTTPAdapter at 0x7fc0120a5ac0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "print(requests.__version__)\n",
    "requests.adapters.HTTPAdapter(max_retries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90fd40-13f4-4d2c-8d21-96dc73d815a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b083d-b26d-4a0e-a0fa-96227310be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
