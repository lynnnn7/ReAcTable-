{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fa0fb0-dbd8-4ec5-8b5d-b9c237455edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54b74f4-099c-4f47-89f2-305d54d6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "# from gpt3_sandbox.api.gpt import GPT\n",
    "# from gpt3_sandbox.api.gpt import Example\n",
    "from pandasql import sqldf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from GptPrompter import *\n",
    "from GptCOTPrompter import *\n",
    "from GptCOTPrompter_BeamSeach import *\n",
    "from AutoReasoner import *\n",
    "import dotenv\n",
    "\n",
    "config = dotenv.dotenv_values(\".env\")\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "\n",
    "dataset = pd.read_csv('./dataset/WikiTableQuestions/data/pristine-unseen-tables.tsv', sep='\\t')\n",
    "# dataset = pd.read_csv('./dataset/WikiTableQuestions/data/training.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793811e9-8737-4d8f-bcbb-274e539de27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213c2d0-01ac-4508-b553-0a58a2ecb067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad51ccf-cda6-47ed-8fb9-8f7f60343867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                                                                                                                                                                             | 30/4344 [00:08<22:28,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8222 tokens (7198 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▊                                                                                                                                                                                                                                                                                                        | 70/4344 [00:54<1:08:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8649 tokens (7625 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████████▉                                                                                                                                                                                                                                                                                                   | 130/4344 [01:59<1:23:36,  1.19s/it]/mnt/GPT-TabQA/GptCOTPrompter.py:47: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  renewed_df = ps.sqldf(code)\n",
      "/mnt/GPT-TabQA/GptCOTPrompter.py:47: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  renewed_df = ps.sqldf(code)\n",
      "  3%|██████████▎                                                                                                                                                                                                                                                                                                 | 150/4344 [02:21<1:19:17,  1.13s/it]/mnt/GPT-TabQA/GptCOTPrompter.py:47: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  renewed_df = ps.sqldf(code)\n",
      "  4%|███████████▋                                                                                                                                                                                                                                                                                                | 170/4344 [02:44<1:16:51,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████████████▍                                                                                                                                                                                                                                                                                               | 180/4344 [02:56<1:18:04,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n",
      "This model's maximum context length is 8193 tokens, however you requested 9572 tokens (8548 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████████████▉                                                                                                                                                                                                                                                                                          | 260/4344 [04:43<1:33:04,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 9292 tokens (8268 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████████████████████▍                                                                                                                                                                                                                                                                                      | 310/4344 [05:43<1:22:23,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.875\n",
      "157.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████████████████▏                                                                                                                                                                                                                                                                                   | 350/4344 [06:44<1:35:07,  1.43s/it]<string>:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "<string>:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "<string>:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "<string>:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "<string>:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████████████████▊                                                                                                                                                                                                                                                                                   | 360/4344 [07:05<1:48:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8559 tokens (7535 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████████████████████████████▊                                                                                                                                                                                                                                                                            | 460/4344 [08:57<1:17:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8238 tokens (7214 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████████████████████████████████▉                                                                                                                                                                                                                                                                      | 550/4344 [10:32<1:14:45,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8663 tokens (7639 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████████████████████████                                                                                                                                                                                                                                                                    | 580/4344 [11:16<1:28:23,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8316 tokens (7292 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████████████████████████▍                                                                                                                                                                                                                                                                  | 600/4344 [11:54<1:49:10,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8289 tokens (7265 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████████████████████████████▏                                                                                                                                                                                                                                                                 | 610/4344 [12:08<1:42:37,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 9613 tokens (8589 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/GPT-TabQA/GptCOTPrompter.py:47: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  renewed_df = ps.sqldf(code)\n",
      " 14%|██████████████████████████████████████████▊                                                                                                                                                                                                                                                                 | 620/4344 [12:23<1:39:43,  1.61s/it]/mnt/GPT-TabQA/GptCOTPrompter.py:47: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  renewed_df = ps.sqldf(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8205 tokens (7181 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████████████████████████████████▌                                                                                                                                                                                                                                                              | 660/4344 [13:16<1:26:17,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8396 tokens (7372 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████████████████████████████████▋                                                                                                                                                                                                                                                            | 690/4344 [13:54<1:22:42,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 9475 tokens (8451 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████████████████████████████████                                                                                                                                                                                                                                                           | 710/4344 [14:29<1:33:48,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████████████████████████████████████▊                                                                                                                                                                                                                                                        | 750/4344 [15:36<1:41:50,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 9083 tokens (8059 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████████████████████████████████████▉                                                                                                                                                                                                                                                    | 810/4344 [17:31<1:48:01,  1.83s/it]/mnt/GPT-TabQA/GptCOTPrompter.py:47: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  renewed_df = ps.sqldf(code)\n",
      " 20%|████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                | 870/4344 [19:07<1:36:39,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                      | 1020/4344 [21:42<59:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8702 tokens (7678 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                                                    | 1050/4344 [22:10<53:58,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                               | 1100/4344 [23:17<1:08:25,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 8904 tokens (7880 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                              | 1110/4344 [23:26<1:01:57,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 days 00:00:00\n",
      "1 days 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                           | 1150/4344 [24:27<1:17:02,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 8193 tokens, however you requested 9555 tokens (8531 in your prompt; 1024 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                     | 1260/4344 [26:09<47:35,  1.08it/s]"
     ]
    }
   ],
   "source": [
    "# change the majority vote to max score\n",
    "\n",
    "NNDemo = False\n",
    "max_demo = 5\n",
    "template = 'original-sql-py'\n",
    "# template = 'formatv1-sql-py'\n",
    "def parallel_codex_func_formatv1(i):\n",
    "    max_retry = 3\n",
    "    while max_retry>0:\n",
    "        try:\n",
    "            codex_prompter = CodexAnswerCOTExecutor_BeamSeach(\n",
    "                                              f'prompt_template/{template}.json',\n",
    "                                              dataset.iloc[i]['id'], \n",
    "                                              dataset.iloc[i]['utterance'], \n",
    "                                              dataset.iloc[i]['context'], \n",
    "                                              dataset.iloc[i]['targetValue'],  \n",
    "                                              base_path='./dataset/WikiTableQuestions/',\n",
    "                                              demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                             )\n",
    "            codex_prompter.max_demo = max_demo\n",
    "            # codex_prompter._gen_gpt_prompt()\n",
    "            codex_prompter._gen_gpt_prompt(NNDemo, ft)\n",
    "            codex_prompter._get_gpt_prediction(beam_size=5)\n",
    "            log = codex_prompter._log_dict()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            log = {\n",
    "                'id': dataset.iloc[i]['id'],\n",
    "                'uncaught_err': str(e)\n",
    "            }\n",
    "            if \"model's maximum context length\" in str(e):\n",
    "                return log\n",
    "            max_retry -= 1\n",
    "    return log\n",
    "    \n",
    "for program in [ 'sql-py']:\n",
    "    n_threads = 10\n",
    "    maxLimit = float('inf')\n",
    "    # maxLimit = 200\n",
    "    from joblib import Parallel, delayed\n",
    "    output_result_file = f'./dataset/WikiTableQuestions/results/CodexAnswerCOTExecutor_BeamSeach_{template}_{program}_NNDemo={NNDemo}_results_pristine-unseen-tables.json'\n",
    "    logs = Parallel(n_jobs=n_threads, require='sharedmem')(delayed(parallel_codex_func_formatv1)(i) for i in tqdm(range(min(maxLimit, dataset.shape[0]))))\n",
    "    json.dump(logs, open(output_result_file, 'w'), indent=4)\n",
    "    # evaluate: \n",
    "    os.system(f'cd ./dataset/WikiTableQuestions/ && python2 evaluator.py ./results/{output_result_file.split(\"/\")[-1]} && cd ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcc71493-de7d-44a9-8bb0-000942e720e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNDemo = False\n",
    "max_demo = 5\n",
    "template = 'original-sql-py'\n",
    "program = 'sql-py'\n",
    "def func(i):\n",
    "    codex_prompter = CodexAnswerCOTExecutor_BeamSeach(\n",
    "                                              f'prompt_template/{template}.json',\n",
    "                                              dataset.iloc[i]['id'], \n",
    "                                              dataset.iloc[i]['utterance'], \n",
    "                                              dataset.iloc[i]['context'], \n",
    "                                              dataset.iloc[i]['targetValue'],  \n",
    "                                              base_path='./dataset/WikiTableQuestions/',\n",
    "                                              demo_file=f'few-shot-demo/WikiTQ-{program}.json',\n",
    "                                             )\n",
    "    codex_prompter.max_demo = max_demo\n",
    "    # codex_prompter._gen_gpt_prompt()\n",
    "    codex_prompter._gen_gpt_prompt(NNDemo, ft)\n",
    "    codex_prompter._get_gpt_prediction(beam_size=5)\n",
    "    log = codex_prompter._log_dict()\n",
    "    return log\n",
    "a = func(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a14496af-6598-4140-a986-cf09abb0d6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'nu-0', 'utterance': 'which country had the most cyclists finish within the top 10?', 'source_csv': './dataset/WikiTableQuestions/csv/203-csv/733.csv', 'target_value': 'Italy', 'predicted_value': 'ESP', 'prompt': 'The database table DF is shown as follows:\\n[HEAD]: name|c_1989|c_1990|c_1991|c_1992|c_1993|c_1994|c_1995|c_1996|c_1997|c_1998|c_1999|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|career_sr|career_win_loss\\n---\\n[ROW] 1: Australian Open|A|A|1R|A|2R|3R|2R|1R|A|3R|4R|1R|2R|1R|3R|2R|1R|QF|3R|2R|3R|1R|0 / 18|22–18\\n[ROW] 2: French Open|1R|2R|4R|1R|1R|3R|1R|A|1R|3R|1R|2R|4R|2R|2R|3R|1R|1R|1R|2R|1R|A|0 / 20|17–20\\n[ROW] 3: Wimbledon|A|1R|A|A|A|A|1R|A|1R|A|2R|2R|3R|2R|2R|2R|2R|2R|2R|1R|2R|A|0 / 14|11–14\\n...\\n[ROW] 17: Annual Win-Loss|nan|2–4|7–5|3–5|6–4|2–1|5–4|2–1|12–6|10–9|10–7|12–9|13–9|9–9|2–7|8–5|7–7|3–8|4–3|2–3|1–2|0–0|nan|120–108\\n[ROW] 18: Year End Ranking|235|62|43|43|55|46|102|118|29|41|34|31|22|35|62|52|58|52|37|52|68|–|nan|nan\\n\\nAnswer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nSQL: ```SELECT name, career_win_loss FROM DF WHERE name=\"Australian Open\" or name=\"Indian Wells\";```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: career_win_loss\\n---\\n[ROW] 1: Australian Open|22–18\\n[ROW] 2: Indian Wells|16-13\\n\\nAnswer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nAnswer: ```Australian Open```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: by_race|white|black|aian*|asian|nhpi*\\n---\\n[ROW] 1: 2000 (total population)|75.43%|4.46%|19.06%|5.24%|0.88%\\n[ROW] 2: 2000 (Hispanic only)|3.42%|0.33%|0.45%|0.16%|0.06%\\n[ROW] 3: 2005 (total population)|74.71%|4.72%|18.77%|5.90%|0.88%\\n...\\n[ROW] 6: Growth 2000–05 (non-Hispanic only)|3.49%|11.30%|4.02%|18.96%|5.86%\\n[ROW] 7: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\\n\\nAnswer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nSQL: ```SELECT * FROM DF WHERE by_race LIKE \"Growth 2000–05 (Hispanic only)%\";```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: by_race|white|black|aian*|asian|nhpi*\\n---\\n[ROW] 1: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\\n\\nAnswer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nAnswer: ```white```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: rank|mountain_peak|mountain_range|elevation|prominence|isolation|location\\n---\\n[ROW] 1: 1|Mount Whitney|Sierra Nevada|14,505 ft 4421 m|10,080 ft 3072 m|1,646 mi 2,649 km|36°34′43″N 118°17′31″W\\ufeff / \\ufeff36.5786°N 118.2920°W\\n[ROW] 2: 2|Mount Williamson|Sierra Nevada|14,379 ft 4383 m|1,677 ft 511 m|5.4 mi 8.7 km|36°39′21″N 118°18′40″W\\ufeff / \\ufeff36.6559°N 118.3111°W\\n[ROW] 3: 3|White Mountain Peak|White Mountains|14,252 ft 4344 m|7,196 ft 2193 m|67 mi 109 km|37°38′03″N 118°15′21″W\\ufeff / \\ufeff37.6341°N 118.2557°W\\n...\\n[ROW] 15: 15|Red Slate Mountain|Sierra Nevada|13,162 ft 4012 m|1,736 ft 529 m|8 mi 13 km|37°30′27″N 118°52′09″W\\ufeff / \\ufeff37.5075°N 118.8693°W\\n[ROW] 16: 16|Mount Ritter|Sierra Nevada|13,149 ft 4008 m|3,990 ft 1216 m|22 mi 35 km|37°41′21″N 119°11′59″W\\ufeff / \\ufeff37.6891°N 119.1996°W\\n\\nAnswer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nSQL: ```SELECT mountain_peak, prominence FROM DF;```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: mountain_peak|prominence\\n---\\n[ROW] 1: Mount Whitney|10,080 ft 3072 m\\n[ROW] 2: Mount Williamson|1,677 ft 511 m\\n[ROW] 3: White Mountain Peak|7,196 ft 2193 m\\n...\\n[ROW] 15: Red Slate Mountain|1,736 ft 529 m\\n[ROW] 16: Mount Ritter|3,990 ft 1216 m\\n\\nAnswer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nPython: ```\\ndef get_ft(s):\\n    import re\\n    return float(re.search(\"(.*?) ft\", s).group(1))\\nDF[\\'prominence_ft\\'] = DF.apply(lambda x: get_ft(x[\\'prominence\\']), axis=1)\\n```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: mountain_peak|prominence|prominence_ft\\n---\\n[ROW] 1: Mount Whitney|10,080 ft 3072 m|10080.0\\n[ROW] 2: Mount Williamson|1,677 ft 511 m|1677.0\\n[ROW] 3: White Mountain Peak|7,196 ft 2193 m|7196.0\\n...\\n[ROW] 15: Red Slate Mountain|1,736 ft 529 m|1736.0\\n[ROW] 16: Mount Ritter|3,990 ft 1216 m|3990.0\\n\\nAnswer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nSQL: ```SELECT mountain_peak FROM DF WHERE prominence_ft>10000;```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: mountain_peak\\n---\\n[ROW] 1: Mount Whitney\\n\\nAnswer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nAnswer: ```Mount Whitney```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: season|division|tms|pos|fa_cup|afc_cl\\n---\\n[ROW] 1: 2003|1|12|11|Quarter final|-\\n[ROW] 2: 2004|1|13|10|Round of 32|-\\n[ROW] 3: 2005|1|13|8|Quarter final|-\\n...\\n[ROW] 9: 2011|1|16|12|Round of 32|-\\n[ROW] 10: 2012|1|16|10|Round of 16|-\\n\\nAnswer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nSQL: ```SELECT fa_cup FROM DF WHERE season>2009;```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: fa_cup\\n---\\n[ROW] 1: Round of 32\\n[ROW] 2: Round of 32\\n[ROW] 3: Round of 16\\n\\nAnswer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nAnswer: ```Round of 16```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: unnamed_0|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|c_2011|c_2012\\n---\\n[ROW] 1: Hydro power|1,150|1,161|1,171|1,247|1,281|1,293|1,316|1,326|1,357|1,379|1,382|1,401|1,584\\n[ROW] 2: Thermal|685|835|1,056|1,233|1,215|1,155|1,155|1,155|1,285|1,290|1,390|1,690|1,638\\n[ROW] 3: Other renewables|3|3|3|3|3|3|3|3|3|15|45|50|90\\n...\\n[ROW] 7: Other renewables|3|3|4|3|3|5|4|4|8|27|86|121|169\\n[ROW] 8: Total production|6,685|6,520|6,167|7,611|8,043|8,770|9,389|9,815|9,901|9,883|10,715|11,528|11,800\\n\\nAnswer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nSQL: ```SELECT c_2010, c_2012 FROM DF WHERE unnamed_0=\"Hydro power\";```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: c_2010|c_2012\\n---\\n[ROW] 1: 1,382|1,584\\n\\nAnswer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n\\nAnswer: ```increase```.\\n\\nThe database table DF is shown as follows:\\n[HEAD]: rank|cyclist|team|time|uci_protour_points\\n---\\n[ROW] 1: 1|Alejandro Valverde (ESP)|Caisse d\\'Epargne|5h 29\\' 10\\\\\",40\"|NULL\\n[ROW] 2: 2|Alexandr Kolobnev (RUS)|Team CSC Saxo Bank|s.t.|30.0\\n[ROW] 3: 3|Davide Rebellin (ITA)|Gerolsteiner|s.t.|25.0\\n[ROW] 4: 4|Paolo Bettini (ITA)|Quick Step|s.t.|20.0\\n[ROW] 5: 5|Franco Pellizotti (ITA)|Liquigas|s.t.|15.0\\n[ROW] 6: 6|Denis Menchov (RUS)|Rabobank|s.t.|11.0\\n[ROW] 7: 7|Samuel Sánchez (ESP)|Euskaltel-Euskadi|s.t.|7.0\\n[ROW] 8: 8|Stéphane Goubert (FRA)|Ag2r-La Mondiale|+ 2\\\\\",5\"|NULL\\n[ROW] 9: 9|Haimar Zubeldia (ESP)|Euskaltel-Euskadi|+ 2\\\\\",3\"|NULL\\n[ROW] 10: 10|David Moncoutié (FRA)|Cofidis|+ 2\\\\\",1\"|NULL\\n\\nAnswer the following question based on the data above: \"which country had the most cyclists finish within the top 10?\". Execute SQL or Python code step-by-step and finally answer the question. Use SQL to process the query and use Python to reformat the data.\\n', 'execution_match': None, 'gpt_error': None, 'execution_err': None, 'predicted_sql': None, 'df_reformat_sql': None, 'gpt_original_output': [], 'all_predictions': {'ESP': -11.784383774516, 'Italy': -11.992692088725999}, 'training_demo_ids': []}\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d656cd6-e6bc-4bf2-93bb-31cd238fbfd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database table DF is shown as follows:\n",
      "[HEAD]: name|c_1989|c_1990|c_1991|c_1992|c_1993|c_1994|c_1995|c_1996|c_1997|c_1998|c_1999|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|career_sr|career_win_loss\n",
      "---\n",
      "[ROW] 1: Australian Open|A|A|1R|A|2R|3R|2R|1R|A|3R|4R|1R|2R|1R|3R|2R|1R|QF|3R|2R|3R|1R|0 / 18|22–18\n",
      "[ROW] 2: French Open|1R|2R|4R|1R|1R|3R|1R|A|1R|3R|1R|2R|4R|2R|2R|3R|1R|1R|1R|2R|1R|A|0 / 20|17–20\n",
      "[ROW] 3: Wimbledon|A|1R|A|A|A|A|1R|A|1R|A|2R|2R|3R|2R|2R|2R|2R|2R|2R|1R|2R|A|0 / 14|11–14\n",
      "...\n",
      "[ROW] 17: Annual Win-Loss|nan|2–4|7–5|3–5|6–4|2–1|5–4|2–1|12–6|10–9|10–7|12–9|13–9|9–9|2–7|8–5|7–7|3–8|4–3|2–3|1–2|0–0|nan|120–108\n",
      "[ROW] 18: Year End Ranking|235|62|43|43|55|46|102|118|29|41|34|31|22|35|62|52|58|52|37|52|68|–|nan|nan\n",
      "\n",
      "Answer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT name, career_win_loss FROM DF WHERE name=\"Australian Open\" or name=\"Indian Wells\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: career_win_loss\n",
      "---\n",
      "[ROW] 1: Australian Open|22–18\n",
      "[ROW] 2: Indian Wells|16-13\n",
      "\n",
      "Answer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Australian Open```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: by_race|white|black|aian*|asian|nhpi*\n",
      "---\n",
      "[ROW] 1: 2000 (total population)|75.43%|4.46%|19.06%|5.24%|0.88%\n",
      "[ROW] 2: 2000 (Hispanic only)|3.42%|0.33%|0.45%|0.16%|0.06%\n",
      "[ROW] 3: 2005 (total population)|74.71%|4.72%|18.77%|5.90%|0.88%\n",
      "...\n",
      "[ROW] 6: Growth 2000–05 (non-Hispanic only)|3.49%|11.30%|4.02%|18.96%|5.86%\n",
      "[ROW] 7: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\n",
      "\n",
      "Answer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT * FROM DF WHERE by_race LIKE \"Growth 2000–05 (Hispanic only)%\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: by_race|white|black|aian*|asian|nhpi*\n",
      "---\n",
      "[ROW] 1: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\n",
      "\n",
      "Answer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```white```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: rank|mountain_peak|mountain_range|elevation|prominence|isolation|location\n",
      "---\n",
      "[ROW] 1: 1|Mount Whitney|Sierra Nevada|14,505 ft 4421 m|10,080 ft 3072 m|1,646 mi 2,649 km|36°34′43″N 118°17′31″W﻿ / ﻿36.5786°N 118.2920°W\n",
      "[ROW] 2: 2|Mount Williamson|Sierra Nevada|14,379 ft 4383 m|1,677 ft 511 m|5.4 mi 8.7 km|36°39′21″N 118°18′40″W﻿ / ﻿36.6559°N 118.3111°W\n",
      "[ROW] 3: 3|White Mountain Peak|White Mountains|14,252 ft 4344 m|7,196 ft 2193 m|67 mi 109 km|37°38′03″N 118°15′21″W﻿ / ﻿37.6341°N 118.2557°W\n",
      "...\n",
      "[ROW] 15: 15|Red Slate Mountain|Sierra Nevada|13,162 ft 4012 m|1,736 ft 529 m|8 mi 13 km|37°30′27″N 118°52′09″W﻿ / ﻿37.5075°N 118.8693°W\n",
      "[ROW] 16: 16|Mount Ritter|Sierra Nevada|13,149 ft 4008 m|3,990 ft 1216 m|22 mi 35 km|37°41′21″N 119°11′59″W﻿ / ﻿37.6891°N 119.1996°W\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT mountain_peak, prominence FROM DF;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak|prominence\n",
      "---\n",
      "[ROW] 1: Mount Whitney|10,080 ft 3072 m\n",
      "[ROW] 2: Mount Williamson|1,677 ft 511 m\n",
      "[ROW] 3: White Mountain Peak|7,196 ft 2193 m\n",
      "...\n",
      "[ROW] 15: Red Slate Mountain|1,736 ft 529 m\n",
      "[ROW] 16: Mount Ritter|3,990 ft 1216 m\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Python: ```\n",
      "def get_ft(s):\n",
      "    import re\n",
      "    return float(re.search(\"(.*?) ft\", s).group(1))\n",
      "DF['prominence_ft'] = DF.apply(lambda x: get_ft(x['prominence']), axis=1)\n",
      "```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak|prominence|prominence_ft\n",
      "---\n",
      "[ROW] 1: Mount Whitney|10,080 ft 3072 m|10080.0\n",
      "[ROW] 2: Mount Williamson|1,677 ft 511 m|1677.0\n",
      "[ROW] 3: White Mountain Peak|7,196 ft 2193 m|7196.0\n",
      "...\n",
      "[ROW] 15: Red Slate Mountain|1,736 ft 529 m|1736.0\n",
      "[ROW] 16: Mount Ritter|3,990 ft 1216 m|3990.0\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT mountain_peak FROM DF WHERE prominence_ft>10000;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak\n",
      "---\n",
      "[ROW] 1: Mount Whitney\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Mount Whitney```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: season|division|tms|pos|fa_cup|afc_cl\n",
      "---\n",
      "[ROW] 1: 2003|1|12|11|Quarter final|-\n",
      "[ROW] 2: 2004|1|13|10|Round of 32|-\n",
      "[ROW] 3: 2005|1|13|8|Quarter final|-\n",
      "...\n",
      "[ROW] 9: 2011|1|16|12|Round of 32|-\n",
      "[ROW] 10: 2012|1|16|10|Round of 16|-\n",
      "\n",
      "Answer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT fa_cup FROM DF WHERE season>2009;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: fa_cup\n",
      "---\n",
      "[ROW] 1: Round of 32\n",
      "[ROW] 2: Round of 32\n",
      "[ROW] 3: Round of 16\n",
      "\n",
      "Answer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Round of 16```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: unnamed_0|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|c_2011|c_2012\n",
      "---\n",
      "[ROW] 1: Hydro power|1,150|1,161|1,171|1,247|1,281|1,293|1,316|1,326|1,357|1,379|1,382|1,401|1,584\n",
      "[ROW] 2: Thermal|685|835|1,056|1,233|1,215|1,155|1,155|1,155|1,285|1,290|1,390|1,690|1,638\n",
      "[ROW] 3: Other renewables|3|3|3|3|3|3|3|3|3|15|45|50|90\n",
      "...\n",
      "[ROW] 7: Other renewables|3|3|4|3|3|5|4|4|8|27|86|121|169\n",
      "[ROW] 8: Total production|6,685|6,520|6,167|7,611|8,043|8,770|9,389|9,815|9,901|9,883|10,715|11,528|11,800\n",
      "\n",
      "Answer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT c_2010, c_2012 FROM DF WHERE unnamed_0=\"Hydro power\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: c_2010|c_2012\n",
      "---\n",
      "[ROW] 1: 1,382|1,584\n",
      "\n",
      "Answer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```increase```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: ship|type_of_vessel|lake|location|lives_lost\n",
      "---\n",
      "[ROW] 1: Argus|Steamer|Lake Huron|25 miles off Kincardine, Ontario|25 lost\n",
      "[ROW] 2: James Carruthers|Steamer|Lake Huron|near Kincardine|18 lost\n",
      "[ROW] 3: Hydrus|Steamer|Lake Huron|near Lexington, Michigan|28 lost\n",
      "[ROW] 4: Leafield|Steamer|Lake Superior|NULL|all hands\n",
      "[ROW] 5: John A. McGean|Steamer|Lake Huron|near Goderich, Ontario|28 lost\n",
      "[ROW] 6: Plymouth|Barge|Lake Michigan|NULL|7 lost\n",
      "[ROW] 7: Charles S. Price|Steamer|Lake Huron|near Port Huron, Michigan|28 lost\n",
      "[ROW] 8: Regina|Steamer|Lake Huron|near Harbor Beach, Michigan|NULL\n",
      "[ROW] 9: Issac M. Scott|Steamer|Lake Huron|near Port Elgin, Ontario|28 lost\n",
      "[ROW] 10: Henry B. Smith|Steamer|Lake Superior|NULL|all hands\n",
      "[ROW] 11: Wexford|Steamer|Lake Huron|north of Grand Bend, Ontario|all hands\n",
      "[ROW] 12: Lightship No. 82|Lightship|Lake Erie|Point Albino (near Buffalo)|6 lost\n",
      "\n",
      "Answer the following question based on the data above: \"how many more ships were wrecked in lake huron than in erie?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT lake, COUNT(*) FROM DF GROUP BY lake;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: lake|count(*)\n",
      "---\n",
      "[ROW] 1: Lake Erie|1\n",
      "[ROW] 2: Lake Huron|8\n",
      "[ROW] 3: Lake Michigan|1\n",
      "[ROW] 4: Lake Superior|2\n",
      "\n",
      "Answer the following question based on the data above: \"how many more ships were wrecked in lake huron than in erie?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a['decision_prompts'][1])\n",
    "# print(a['action_prompts'][0])\n",
    "\n",
    "# print(a['gpt_original_output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6954b8b-6241-43d5-960c-8600ebb9b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database table DF is shown as follows:\n",
      "[HEAD]: name|c_1989|c_1990|c_1991|c_1992|c_1993|c_1994|c_1995|c_1996|c_1997|c_1998|c_1999|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|career_sr|career_win_loss\n",
      "---\n",
      "[ROW] 1: Australian Open|A|A|1R|A|2R|3R|2R|1R|A|3R|4R|1R|2R|1R|3R|2R|1R|QF|3R|2R|3R|1R|0 / 18|22–18\n",
      "[ROW] 2: French Open|1R|2R|4R|1R|1R|3R|1R|A|1R|3R|1R|2R|4R|2R|2R|3R|1R|1R|1R|2R|1R|A|0 / 20|17–20\n",
      "[ROW] 3: Wimbledon|A|1R|A|A|A|A|1R|A|1R|A|2R|2R|3R|2R|2R|2R|2R|2R|2R|1R|2R|A|0 / 14|11–14\n",
      "...\n",
      "[ROW] 17: Annual Win-Loss|nan|2–4|7–5|3–5|6–4|2–1|5–4|2–1|12–6|10–9|10–7|12–9|13–9|9–9|2–7|8–5|7–7|3–8|4–3|2–3|1–2|0–0|nan|120–108\n",
      "[ROW] 18: Year End Ranking|235|62|43|43|55|46|102|118|29|41|34|31|22|35|62|52|58|52|37|52|68|–|nan|nan\n",
      "\n",
      "Answer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT name, career_win_loss FROM DF WHERE name=\"Australian Open\" or name=\"Indian Wells\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: career_win_loss\n",
      "---\n",
      "[ROW] 1: Australian Open|22–18\n",
      "[ROW] 2: Indian Wells|16-13\n",
      "\n",
      "Answer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Australian Open```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: by_race|white|black|aian*|asian|nhpi*\n",
      "---\n",
      "[ROW] 1: 2000 (total population)|75.43%|4.46%|19.06%|5.24%|0.88%\n",
      "[ROW] 2: 2000 (Hispanic only)|3.42%|0.33%|0.45%|0.16%|0.06%\n",
      "[ROW] 3: 2005 (total population)|74.71%|4.72%|18.77%|5.90%|0.88%\n",
      "...\n",
      "[ROW] 6: Growth 2000–05 (non-Hispanic only)|3.49%|11.30%|4.02%|18.96%|5.86%\n",
      "[ROW] 7: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\n",
      "\n",
      "Answer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT * FROM DF WHERE by_race LIKE \"Growth 2000–05 (Hispanic only)%\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: by_race|white|black|aian*|asian|nhpi*\n",
      "---\n",
      "[ROW] 1: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\n",
      "\n",
      "Answer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```white```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: rank|mountain_peak|mountain_range|elevation|prominence|isolation|location\n",
      "---\n",
      "[ROW] 1: 1|Mount Whitney|Sierra Nevada|14,505 ft 4421 m|10,080 ft 3072 m|1,646 mi 2,649 km|36°34′43″N 118°17′31″W﻿ / ﻿36.5786°N 118.2920°W\n",
      "[ROW] 2: 2|Mount Williamson|Sierra Nevada|14,379 ft 4383 m|1,677 ft 511 m|5.4 mi 8.7 km|36°39′21″N 118°18′40″W﻿ / ﻿36.6559°N 118.3111°W\n",
      "[ROW] 3: 3|White Mountain Peak|White Mountains|14,252 ft 4344 m|7,196 ft 2193 m|67 mi 109 km|37°38′03″N 118°15′21″W﻿ / ﻿37.6341°N 118.2557°W\n",
      "...\n",
      "[ROW] 15: 15|Red Slate Mountain|Sierra Nevada|13,162 ft 4012 m|1,736 ft 529 m|8 mi 13 km|37°30′27″N 118°52′09″W﻿ / ﻿37.5075°N 118.8693°W\n",
      "[ROW] 16: 16|Mount Ritter|Sierra Nevada|13,149 ft 4008 m|3,990 ft 1216 m|22 mi 35 km|37°41′21″N 119°11′59″W﻿ / ﻿37.6891°N 119.1996°W\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT mountain_peak, prominence FROM DF;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak|prominence\n",
      "---\n",
      "[ROW] 1: Mount Whitney|10,080 ft 3072 m\n",
      "[ROW] 2: Mount Williamson|1,677 ft 511 m\n",
      "[ROW] 3: White Mountain Peak|7,196 ft 2193 m\n",
      "...\n",
      "[ROW] 15: Red Slate Mountain|1,736 ft 529 m\n",
      "[ROW] 16: Mount Ritter|3,990 ft 1216 m\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Python: ```\n",
      "def get_ft(s):\n",
      "    import re\n",
      "    return float(re.search(\"(.*?) ft\", s).group(1))\n",
      "DF['prominence_ft'] = DF.apply(lambda x: get_ft(x['prominence']), axis=1)\n",
      "```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak|prominence|prominence_ft\n",
      "---\n",
      "[ROW] 1: Mount Whitney|10,080 ft 3072 m|10080.0\n",
      "[ROW] 2: Mount Williamson|1,677 ft 511 m|1677.0\n",
      "[ROW] 3: White Mountain Peak|7,196 ft 2193 m|7196.0\n",
      "...\n",
      "[ROW] 15: Red Slate Mountain|1,736 ft 529 m|1736.0\n",
      "[ROW] 16: Mount Ritter|3,990 ft 1216 m|3990.0\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT mountain_peak FROM DF WHERE prominence_ft>10000;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak\n",
      "---\n",
      "[ROW] 1: Mount Whitney\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Mount Whitney```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: season|division|tms|pos|fa_cup|afc_cl\n",
      "---\n",
      "[ROW] 1: 2003|1|12|11|Quarter final|-\n",
      "[ROW] 2: 2004|1|13|10|Round of 32|-\n",
      "[ROW] 3: 2005|1|13|8|Quarter final|-\n",
      "...\n",
      "[ROW] 9: 2011|1|16|12|Round of 32|-\n",
      "[ROW] 10: 2012|1|16|10|Round of 16|-\n",
      "\n",
      "Answer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT fa_cup FROM DF WHERE season>2009;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: fa_cup\n",
      "---\n",
      "[ROW] 1: Round of 32\n",
      "[ROW] 2: Round of 32\n",
      "[ROW] 3: Round of 16\n",
      "\n",
      "Answer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Round of 16```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: unnamed_0|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|c_2011|c_2012\n",
      "---\n",
      "[ROW] 1: Hydro power|1,150|1,161|1,171|1,247|1,281|1,293|1,316|1,326|1,357|1,379|1,382|1,401|1,584\n",
      "[ROW] 2: Thermal|685|835|1,056|1,233|1,215|1,155|1,155|1,155|1,285|1,290|1,390|1,690|1,638\n",
      "[ROW] 3: Other renewables|3|3|3|3|3|3|3|3|3|15|45|50|90\n",
      "...\n",
      "[ROW] 7: Other renewables|3|3|4|3|3|5|4|4|8|27|86|121|169\n",
      "[ROW] 8: Total production|6,685|6,520|6,167|7,611|8,043|8,770|9,389|9,815|9,901|9,883|10,715|11,528|11,800\n",
      "\n",
      "Answer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT c_2010, c_2012 FROM DF WHERE unnamed_0=\"Hydro power\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: c_2010|c_2012\n",
      "---\n",
      "[ROW] 1: 1,382|1,584\n",
      "\n",
      "Answer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```increase```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: pos|no|driver|team|engine|laps|time_retired|grid|laps_led|points\n",
      "---\n",
      "[ROW] 1: 1|2|Ryan Briscoe|Team Penske|Chevrolet|85|2:07:02.8248|2|27|50\n",
      "[ROW] 2: 2|12|Will Power|Team Penske|Chevrolet|85|+ 0.4408|1|57|43\n",
      "[ROW] 3: 3|10|Dario Franchitti|Chip Ganassi Racing|Honda|85|+ 1.0497|6|0|35\n",
      "[ROW] 4: 4|8|Rubens Barrichello|KV Racing Technology|Chevrolet|85|+ 8.8529|11|0|32\n",
      "[ROW] 5: 5|38|Graham Rahal|Chip Ganassi Racing|Honda|85|+ 9.4667|13|0|30\n",
      "[ROW] 6: 6|3|Hélio Castroneves|Team Penske|Chevrolet|85|+ 11.2575|4|0|28\n",
      "[ROW] 7: 7|77|Simon Pagenaud (R)|Schmidt Hamilton Motorsports|Honda|85|+ 12.3087|9|0|26\n",
      "[ROW] 8: 8|4|J.R. Hildebrand|Panther Racing|Chevrolet|85|+ 22.8121|15|0|24\n",
      "[ROW] 9: 9|98|Alex Tagliani|Team Barracuda – BHA|Honda|85|+ 39.6868|8|0|22\n",
      "[ROW] 10: 10|11|Tony Kanaan|KV Racing Technology|Chevrolet|84|+ 1 lap|16|0|20\n",
      "[ROW] 11: 11|18|Justin Wilson|Dale Coyne Racing|Honda|84|+ 1 lap|20|0|19\n",
      "[ROW] 12: 12|19|James Jakes|Dale Coyne Racing|Honda|84|+ 1 lap|24|0|18\n",
      "[ROW] 13: 13|9|Scott Dixon|Chip Ganassi Racing|Honda|84|+ 1 lap|5|0|17\n",
      "[ROW] 14: 14|14|Mike Conway|A.J. Foyt Enterprises|Honda|84|+ 1 lap|14|0|16\n",
      "[ROW] 15: 15|17|Sebastián Saavedra|Andretti Autosport|Chevrolet|84|+ 1 lap|23|0|15\n",
      "[ROW] 16: 16|5|E.J. Viso|KV Racing Technology|Chevrolet|84|+ 1 lap|17|0|14\n",
      "[ROW] 17: 17|78|Simona de Silvestro|HVM Racing|Lotus|84|+ 1 lap|27|0|13\n",
      "[ROW] 18: 18|28|Ryan Hunter-Reay|Andretti Autosport|Chevrolet|84|+ 1 lap|7|1|12\n",
      "...\n",
      "[ROW] 26: 26|27|James Hinchcliffe|Andretti Autosport|Chevrolet|35|Mechanical|10|0|10\n",
      "[ROW] 27: 27|15|Takuma Sato|Rahal Letterman Lanigan Racing|Honda|2|Mechanical|26|0|10\n",
      "\n",
      "Answer the following question based on the data above: \"who is the next driver listed after scott dixon?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT driver FROM DF WHERE pos=9;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: driver\n",
      "---\n",
      "[ROW] 1: Alex Tagliani\n",
      "\n",
      "Answer the following question based on the data above: \"who is the next driver listed after scott dixon?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Alex Tagliani```.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "720442cb-7e13-4bcb-9b19-3f160a619447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database table DF is shown as follows:\n",
      "[HEAD]: name|c_1989|c_1990|c_1991|c_1992|c_1993|c_1994|c_1995|c_1996|c_1997|c_1998|c_1999|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|career_sr|career_win_loss\n",
      "---\n",
      "[ROW] 1: Australian Open|A|A|1R|A|2R|3R|2R|1R|A|3R|4R|1R|2R|1R|3R|2R|1R|QF|3R|2R|3R|1R|0 / 18|22–18\n",
      "[ROW] 2: French Open|1R|2R|4R|1R|1R|3R|1R|A|1R|3R|1R|2R|4R|2R|2R|3R|1R|1R|1R|2R|1R|A|0 / 20|17–20\n",
      "[ROW] 3: Wimbledon|A|1R|A|A|A|A|1R|A|1R|A|2R|2R|3R|2R|2R|2R|2R|2R|2R|1R|2R|A|0 / 14|11–14\n",
      "...\n",
      "[ROW] 17: Annual Win-Loss|nan|2–4|7–5|3–5|6–4|2–1|5–4|2–1|12–6|10–9|10–7|12–9|13–9|9–9|2–7|8–5|7–7|3–8|4–3|2–3|1–2|0–0|nan|120–108\n",
      "[ROW] 18: Year End Ranking|235|62|43|43|55|46|102|118|29|41|34|31|22|35|62|52|58|52|37|52|68|–|nan|nan\n",
      "\n",
      "Answer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT name, career_win_loss FROM DF WHERE name=\"Australian Open\" or name=\"Indian Wells\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: career_win_loss\n",
      "---\n",
      "[ROW] 1: Australian Open|22–18\n",
      "[ROW] 2: Indian Wells|16-13\n",
      "\n",
      "Answer the following question based on the data above: \"did he win more at the australian open or indian wells?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Australian Open```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: by_race|white|black|aian*|asian|nhpi*\n",
      "---\n",
      "[ROW] 1: 2000 (total population)|75.43%|4.46%|19.06%|5.24%|0.88%\n",
      "[ROW] 2: 2000 (Hispanic only)|3.42%|0.33%|0.45%|0.16%|0.06%\n",
      "[ROW] 3: 2005 (total population)|74.71%|4.72%|18.77%|5.90%|0.88%\n",
      "...\n",
      "[ROW] 6: Growth 2000–05 (non-Hispanic only)|3.49%|11.30%|4.02%|18.96%|5.86%\n",
      "[ROW] 7: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\n",
      "\n",
      "Answer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT * FROM DF WHERE by_race LIKE \"Growth 2000–05 (Hispanic only)%\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: by_race|white|black|aian*|asian|nhpi*\n",
      "---\n",
      "[ROW] 1: Growth 2000–05 (Hispanic only)|33.56%|21.02%|14.52%|27.89%|-1.95%\n",
      "\n",
      "Answer the following question based on the data above: \"which hispanic population had the greatest growth from 2000 to 2005?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```white```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: rank|mountain_peak|mountain_range|elevation|prominence|isolation|location\n",
      "---\n",
      "[ROW] 1: 1|Mount Whitney|Sierra Nevada|14,505 ft 4421 m|10,080 ft 3072 m|1,646 mi 2,649 km|36°34′43″N 118°17′31″W﻿ / ﻿36.5786°N 118.2920°W\n",
      "[ROW] 2: 2|Mount Williamson|Sierra Nevada|14,379 ft 4383 m|1,677 ft 511 m|5.4 mi 8.7 km|36°39′21″N 118°18′40″W﻿ / ﻿36.6559°N 118.3111°W\n",
      "[ROW] 3: 3|White Mountain Peak|White Mountains|14,252 ft 4344 m|7,196 ft 2193 m|67 mi 109 km|37°38′03″N 118°15′21″W﻿ / ﻿37.6341°N 118.2557°W\n",
      "...\n",
      "[ROW] 15: 15|Red Slate Mountain|Sierra Nevada|13,162 ft 4012 m|1,736 ft 529 m|8 mi 13 km|37°30′27″N 118°52′09″W﻿ / ﻿37.5075°N 118.8693°W\n",
      "[ROW] 16: 16|Mount Ritter|Sierra Nevada|13,149 ft 4008 m|3,990 ft 1216 m|22 mi 35 km|37°41′21″N 119°11′59″W﻿ / ﻿37.6891°N 119.1996°W\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT mountain_peak, prominence FROM DF;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak|prominence\n",
      "---\n",
      "[ROW] 1: Mount Whitney|10,080 ft 3072 m\n",
      "[ROW] 2: Mount Williamson|1,677 ft 511 m\n",
      "[ROW] 3: White Mountain Peak|7,196 ft 2193 m\n",
      "...\n",
      "[ROW] 15: Red Slate Mountain|1,736 ft 529 m\n",
      "[ROW] 16: Mount Ritter|3,990 ft 1216 m\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Python: ```\n",
      "def get_ft(s):\n",
      "    import re\n",
      "    return float(re.search(\"(.*?) ft\", s).group(1))\n",
      "DF['prominence_ft'] = DF.apply(lambda x: get_ft(x['prominence']), axis=1)\n",
      "```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak|prominence|prominence_ft\n",
      "---\n",
      "[ROW] 1: Mount Whitney|10,080 ft 3072 m|10080.0\n",
      "[ROW] 2: Mount Williamson|1,677 ft 511 m|1677.0\n",
      "[ROW] 3: White Mountain Peak|7,196 ft 2193 m|7196.0\n",
      "...\n",
      "[ROW] 15: Red Slate Mountain|1,736 ft 529 m|1736.0\n",
      "[ROW] 16: Mount Ritter|3,990 ft 1216 m|3990.0\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT mountain_peak FROM DF WHERE prominence_ft>10000;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: mountain_peak\n",
      "---\n",
      "[ROW] 1: Mount Whitney\n",
      "\n",
      "Answer the following question based on the data above: \"which mountain peak has a prominence more than 10,000 ft?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Mount Whitney```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: season|division|tms|pos|fa_cup|afc_cl\n",
      "---\n",
      "[ROW] 1: 2003|1|12|11|Quarter final|-\n",
      "[ROW] 2: 2004|1|13|10|Round of 32|-\n",
      "[ROW] 3: 2005|1|13|8|Quarter final|-\n",
      "...\n",
      "[ROW] 9: 2011|1|16|12|Round of 32|-\n",
      "[ROW] 10: 2012|1|16|10|Round of 16|-\n",
      "\n",
      "Answer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT fa_cup FROM DF WHERE season>2009;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: fa_cup\n",
      "---\n",
      "[ROW] 1: Round of 32\n",
      "[ROW] 2: Round of 32\n",
      "[ROW] 3: Round of 16\n",
      "\n",
      "Answer the following question based on the data above: \"how far did they make it in the fa cup after 2009?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```Round of 16```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: unnamed_0|c_2000|c_2001|c_2002|c_2003|c_2004|c_2005|c_2006|c_2007|c_2008|c_2009|c_2010|c_2011|c_2012\n",
      "---\n",
      "[ROW] 1: Hydro power|1,150|1,161|1,171|1,247|1,281|1,293|1,316|1,326|1,357|1,379|1,382|1,401|1,584\n",
      "[ROW] 2: Thermal|685|835|1,056|1,233|1,215|1,155|1,155|1,155|1,285|1,290|1,390|1,690|1,638\n",
      "[ROW] 3: Other renewables|3|3|3|3|3|3|3|3|3|15|45|50|90\n",
      "...\n",
      "[ROW] 7: Other renewables|3|3|4|3|3|5|4|4|8|27|86|121|169\n",
      "[ROW] 8: Total production|6,685|6,520|6,167|7,611|8,043|8,770|9,389|9,815|9,901|9,883|10,715|11,528|11,800\n",
      "\n",
      "Answer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT c_2010, c_2012 FROM DF WHERE unnamed_0=\"Hydro power\";```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: c_2010|c_2012\n",
      "---\n",
      "[ROW] 1: 1,382|1,584\n",
      "\n",
      "Answer the following question based on the data above: \"did the hydro power increase or decrease from 2010 to 2012?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```increase```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: ship|type_of_vessel|lake|location|lives_lost\n",
      "---\n",
      "[ROW] 1: Argus|Steamer|Lake Huron|25 miles off Kincardine, Ontario|25 lost\n",
      "[ROW] 2: James Carruthers|Steamer|Lake Huron|near Kincardine|18 lost\n",
      "[ROW] 3: Hydrus|Steamer|Lake Huron|near Lexington, Michigan|28 lost\n",
      "[ROW] 4: Leafield|Steamer|Lake Superior|NULL|all hands\n",
      "[ROW] 5: John A. McGean|Steamer|Lake Huron|near Goderich, Ontario|28 lost\n",
      "[ROW] 6: Plymouth|Barge|Lake Michigan|NULL|7 lost\n",
      "[ROW] 7: Charles S. Price|Steamer|Lake Huron|near Port Huron, Michigan|28 lost\n",
      "[ROW] 8: Regina|Steamer|Lake Huron|near Harbor Beach, Michigan|NULL\n",
      "[ROW] 9: Issac M. Scott|Steamer|Lake Huron|near Port Elgin, Ontario|28 lost\n",
      "[ROW] 10: Henry B. Smith|Steamer|Lake Superior|NULL|all hands\n",
      "[ROW] 11: Wexford|Steamer|Lake Huron|north of Grand Bend, Ontario|all hands\n",
      "[ROW] 12: Lightship No. 82|Lightship|Lake Erie|Point Albino (near Buffalo)|6 lost\n",
      "\n",
      "Answer the following question based on the data above: \"how many more ships were wrecked in lake huron than in erie?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "SQL: ```SELECT lake, COUNT(*) FROM DF GROUP BY lake;```.\n",
      "\n",
      "The database table DF is shown as follows:\n",
      "[HEAD]: lake|count(*)\n",
      "---\n",
      "[ROW] 1: Lake Erie|1\n",
      "[ROW] 2: Lake Huron|8\n",
      "[ROW] 3: Lake Michigan|1\n",
      "[ROW] 4: Lake Superior|2\n",
      "\n",
      "Answer the following question based on the data above: \"how many more ships were wrecked in lake huron than in erie?\". Execute SQL or Python code step-by-step and finally answer the question. Choose from generating a SQL, Python code, or directly answering the question.\n",
      "\n",
      "Answer: ```7```.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a05ddc-a700-4062-85ac-7f70ecd46e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
